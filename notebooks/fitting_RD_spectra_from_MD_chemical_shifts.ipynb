{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2072ff9-2968-4ab8-a34d-bd7c9e2381b3",
   "metadata": {},
   "source": [
    "# Fitting a stretched CPMG function to the relaxation dispersion spectra derived from chemical shifts of MD trejcotry frames\n",
    "\n",
    "## Steps\n",
    "\n",
    "0. Predict chemical shifts from the MD trajecotry frames using e.g. [SPARTA+](https://doi.org/10.1007/s10858-010-9433-9).\n",
    "1. Calcualte the RD spectra using Fourier transformation with proper normalization.\n",
    "2. Fit a stretched CPMG function using [pymc](https://doi.org/10.7717/peerj-cs.1516)\n",
    "\n",
    "\n",
    "## Theory \n",
    "\n",
    "RD profiles were calculated from our MD simulations via the power spectrum of the combined chemical shift time traces CSHN(t), calculated for all available trajectories of the respective nuclei. Chemical shifts of the p53-TAD backbone protons were predicted using the software SPARTA+ (91) from simulation frames separated 100 ps in time from 20 Œºs trajectories for the WT and 60 Œºs trajectories for the P27A system. As shown by Xue et al. earlier, the RD spectrum is derived from the chemical shift autocorrelation functions (94, 95), which we have calculated from CSHN(t) via the properly normalized power spectrum, i.e., the absolute-squared Fourier transform\n",
    "\n",
    "$ R_{2,ex}\\left(\\nu\\right)\\frac{1}{2}N\\Delta t=\\left|\\mathcal{F}\\left(CS_{NH}\\left(t\\right)\\right)\\right|^2   $\n",
    "\n",
    "using the Wiener-Khinchin theorem (96). Here, ùúà is the CPMG frequency, N is the number of simulation frames, Œît is the time step between frames (100 ps). Note that the unit of CSHN(t) is rad/s. RD profiles were calculated separately from each MD trajectory and then averaged.\n",
    "\n",
    "The analytical form of CPMG profiles for a two-state model (44, 100) is\n",
    "\n",
    "$ R_{2,MD}\\left(\\nu\\right)=\\phi\\tau\\left(1-4\\nu\\tau\\ tanh\\frac{1}{4\\nu\\tau}\\right) $\n",
    "\n",
    "Here, ùúà is the CPMG frequency, Œ¶ = pA pB ŒîCS2 is the population weighted chemical shift variance, pA and pB are the populations of the two states A and B of the model, respectively, and ŒîCS is the chemical shift difference between these two states.\n",
    "Inspired by the shape of the RD profiles calculated from the simulations, which in the logarithmic plot appears to be ‚Äòstretched‚Äô in the frequency domain relative to the CPMG two-state model, a generalized model in terms of a ‚Äòstretched‚Äô function was considered,\n",
    "\n",
    "$ R_{2,MD}\\left(\\nu\\right)=\\phi\\tau\\left(1-\\left(4\\nu\\tau\\right)^\\gamma\\ tanh\\frac{1}{\\left(4\\nu\\tau\\right)^\\gamma}\\right) $\n",
    "\n",
    "similar in spirit to the ‚Äòstretched exponential functions‚Äô used by Frauenfelder to describe the multi-tier dynamics of folded proteins (5, 101, 102). The function can be interpreted as a weighted superposition of many two-state CPMG profiles, with a broad range of characteristic timescales, which is described by the additional fitting parameter ùõæ. Accordingly, ùõæ also characterizes the distribution width of barrier heights governing p53-TAD dynamics, namely ùõæ = 1 indicate a two-state process and the smaller the value the broader the timescale distribution is.\n",
    "\n",
    "Fitting was perfomred using a Bayesian approach (104) with the pymc5 Python package (105), with ùúè and Œ¶ and, ùõæ as free parameters to be determined. The fact that all RD profiles were calculated by averaging over 30 individual RD profiles, each calculated from an absolute-squared Fourier transform of chemical shift trajectories, required particular attention. Notably, Fourier transforms calculated numerically from finite time series are notoriously noisy, and the distribution of each individual (absolute squared) Fourier coefficient $ R_k := R_2(ùúà_k) $ for realizations with a uniform distribution of random phases follows an exponential function (106),\n",
    "\n",
    "$ p\\left(R_k\\right)=\\frac{1}{R_k^0}e^{-\\frac{R_k}{R_k^0}} $\n",
    "\n",
    "where $ p(R_k^0) $ is the true coefficient from which the realizations were drawn. Hence, the probability distribution of the mean $ {\\bar{R}}_k $ of N=30 Fourier transforms of realizations of the same process (the phases of which are assumed to be statistically independent and uniformly distributed) follows a gamma distribution\n",
    "\n",
    "$ p\\left({\\bar{R}}_k\\right)=\\frac{\\beta^N{\\bar{R}}_k^{N-1}e^{-\\beta{\\bar{R}}_k}}{\\Gamma\\left(N\\right)} $\n",
    "\n",
    "where  $ \\beta=\\frac{N}{{\\bar{R}}_k} $\n",
    "\n",
    "Accordingly, this probability distribution was used (instead of a Gaussian distribution) for the Bayesian fit of each Fourier coefficient, with the fitting target $ {\\bar{R}}_k $. A log-uniform prior distribution between $ 10^3 -10^9 Hz^2 $ was used for Œ¶, a log-uniform prior between 1 ns-100 Œºs for ùúè, and a uniform prior between 0-2 for ùõæ.\n",
    "\n",
    "Note: references follow the numbering of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02389610-3b3c-4398-958d-65215402c217",
   "metadata": {},
   "source": [
    "## Calculation of the RD spectra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f710d2-ca03-4cd4-a59a-0988b9fafe0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:20:54.663632Z",
     "iopub.status.busy": "2025-01-07T13:20:54.663135Z",
     "iopub.status.idle": "2025-01-07T13:20:54.693757Z",
     "shell.execute_reply": "2025-01-07T13:20:54.693134Z",
     "shell.execute_reply.started": "2025-01-07T13:20:54.663587Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pymc as pm \n",
    "import pandas as pd\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "# input file name stem (used with glob to get a list of chemical shift files)\n",
    "infile = \"/path/to/chemical_shift_files_*.dat\"\n",
    "# Larmor frequency of the NMR experiment in MHz\n",
    "Larmor = 1200.236\n",
    "#time step of chemical shift time traces in seconds\n",
    "dt = 1e-10\n",
    "#the number of points considered for the fitting, starting with the lowest frequency. \n",
    "wmax = 500\n",
    "#output path stem\n",
    "out_path = \"/path/to/output_\"\n",
    "\n",
    "#define the fitted CPMG function\n",
    "def CPMG_stretched(nu,Phi,tau,stretch_factor):\n",
    "    return Phi*tau * (1 - (4*nu*tau)**stretch_factor * np.tanh(1 / (4*nu*tau)**stretch_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f1bf9a-2ae2-46ac-9475-20d58afafed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T13:12:17.284010Z",
     "iopub.status.busy": "2025-01-07T13:12:17.283731Z",
     "iopub.status.idle": "2025-01-07T13:12:17.288901Z",
     "shell.execute_reply": "2025-01-07T13:12:17.288341Z",
     "shell.execute_reply.started": "2025-01-07T13:12:17.283977Z"
    }
   },
   "outputs": [],
   "source": [
    "#chemical shft file list\n",
    "CS_file_list = glob.glob(infile)\n",
    "\n",
    "#determine the length of the files\n",
    "with open(CS_file_list[0]) as f:\n",
    "    N = sum(1 for _ in f)\n",
    "\n",
    "#determine the frequencies, ùúà\n",
    "nu = np.arange(N) / (dt*N)\n",
    "\n",
    "#contained for the fft results, maximum frequency  points √ó trajectories\n",
    "fft_MD = np.zeros((wmax,len(CS_file_list))) \n",
    "\n",
    "#iterate over the time traces\n",
    "for i,F in enumerate(CS_file_list):\n",
    "    CS = np.loadtxt(F,max_rows=N, usecols=1)\n",
    "    \n",
    "    fftemp = fft(CS*2*np.pi*Larmor,norm=\"forward\")\n",
    "    fft_MD[:,i] = np.abs(fftemp[:wmax]) * np.abs(fftemp[:wmax])\n",
    "\n",
    "#normalize the power spectra to get the RD of each trace.\n",
    "fft_MD = 0.5 * dt * N * fft_MD # do all the scaling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcc79f-b8d2-4519-be01-98a960988ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sum of the traces which is going to be fitted\n",
    "R2 = np.sum(fft_MD[1:,:],axis=1) \n",
    "#limit the frequency range\n",
    "nu = nu[np.arange(1,wmax)]\n",
    "\n",
    "#set up pymc model and sample\n",
    "with pm.Model() as model_MD_stretched:\n",
    "    #log-uniform prior\n",
    "    Phi_power = pm.Uniform('Phi_power', 3, 9)\n",
    "    Phi = pm.Deterministic('Phi', 10**Phi_power)\n",
    "    #power for loguniform tau\n",
    "    tau_power = pm.Uniform('tau_power', -9, -4) \n",
    "    tau = pm.Deterministic('tau',10**tau_power)\n",
    "    stretch_factor = pm.Uniform('stretch_factor', 0, 2)\n",
    "\n",
    "    #parameters for gamma distribution\n",
    "    alpha = len(CS_file_list) # number of fft summed\n",
    "    beta = alpha / CPMG_noR0_stretched(nu, Phi, tau, stretch_factor)\n",
    "    sigma = pm.math.sqrt(alpha / (beta**2))\n",
    "\n",
    "    #the likelyhood\n",
    "    R2_pred = pm.Gamma('R2_pred', mu=CPMG_noR0_stretched(nu, Phi, tau, stretch_factor) , sigma=sigma, observed=R2)\n",
    "    #sampling\n",
    "    trace_MD_stretched = pm.sample(2000, tune=1000,chains=4, cores=4, return_inferencedata=True,target_accept=0.99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c47935-14b3-46b1-869d-ae7684a4201e",
   "metadata": {},
   "source": [
    "## extract parameters and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086bfd8-9123-4e6f-ac55-f98129712f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#----- take from all bootstrap round the last 1000 samples and put them into a big dataframe\n",
    "#                                               samples*chains \n",
    "output_df = pd.DataFrame(np.zeros((bootstrap_rounds*1000*4,4)), columns=[\"Phi\",\"tau\",\"stretch_factor\"])\n",
    "\n",
    "Phis = []\n",
    "taus = []\n",
    "stretch_factors = []\n",
    "\n",
    "for j,trace_MD_stretched in enumerate(trace_list):\n",
    "    #Phi is scaled to get the mean parameter for the mean traces instead of the sum\n",
    "    Phis.append(np.ravel(trace_MD_stretched.posterior[\"Phi\"].values[:,1000:]) / len(CS_file_list) ) # take only last half of sampling, scaled by number of repeats\n",
    "    taus.append(np.ravel(trace_MD_stretched.posterior[\"tau\"].values[:,1000:]))\n",
    "    stretch_factors.append(np.ravel(trace_MD_stretched.posterior[\"stretch_factor\"].values[:,1000:]))\n",
    "           \n",
    "output_df[\"Phi\"] = np.concatenate(Phis)\n",
    "output_df[\"tau\"] = np.concatenate(taus)\n",
    "output_df[\"stretch_factor\"] = np.concatenate(stretch_factors)\n",
    "\n",
    "#save data frame of parameters\n",
    "output_df.to_pickle(out_path+\"fit_parameter_trace.gz\", compression='infer', protocol=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
